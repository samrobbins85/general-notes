---
title: Introduction to Probability
---

# Axioms of Probability

![Axioms of probability](/img/Uni/DADS/Intro/axioms.png)

This then leads to further rules

![Further Rules](/img/Uni/DADS/Intro/further_rules.png)

# Conditional Probability

![Conditional Probability](/img/Uni/DADS/Intro/conditional_probability.png)

# Uniform Distribution

![Uniform Distribution](/img/Uni/DADS/Intro/uniform_distribution.png)

# Independent Probabilities

![Independent](/img/Uni/DADS/Intro/independent.png)

## Pairwise Independence

![Pairwise Independence](/img/Uni/DADS/Intro/pairwise_independent.png)

Every pair of events are independent of each other

## Mutual Independence

The probability of all of a subset of events happening in the multiplication

![Mutual Independence](/img/Uni/DADS/Intro/mutual_independent.png)

# Random variable

![Random Variable](/img/Uni/DADS/Intro/random_variable.png)

The probability that a variable takes a certain value

## Independence

![Independence](/img/Uni/DADS/Intro/independence.png)

The probability $A=x$ and $B=y$ is the probability $A=x$ multiplied by the probability $B=y$

## Expected value

![Expected Value](/img/Uni/DADS/Intro/expected.png)

The expected value is x times the probability of x for all x

This can also be shown as the area under the curve

## Linearity of expectation

![Linearity of Expectation](/img/Uni/DADS/Intro/linearity_of_expectation.png)

The expected value of A and B is the expected value of A plus the expected value of B

**This doesn't apply for multiplication, only if they are independent**
